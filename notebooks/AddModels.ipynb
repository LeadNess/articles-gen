{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.markov import MarkovModel, WordsEncoder\n",
    "from models.utils import get_ram_model\n",
    "from models.utils.mongo import MongoStorage\n",
    "from models.utils.postgres import PostgresStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_storage = MongoStorage.connect(\n",
    "            host='localhost')\n",
    "postgres_storage = PostgresStorage.connect(\n",
    "            host='172.17.0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get posts and articles\n",
      "Get text_gen\n",
      "Complete training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.markov.markov_model.MarkovModel at 0x7f505da52650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_ram_model(\n",
    "    mongo_storage=mongo_storage,\n",
    "    postgres_storage=postgres_storage,\n",
    "    wiki_articles_count=1,\n",
    "    habr_posts_count=-1,\n",
    "    habs_list=['Математика']    \n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('math_habs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get posts and articles\n",
      "Get text_gen\n",
      "Complete training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.markov.markov_model.MarkovModel at 0x7f50297ce7d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_ram_model(\n",
    "    mongo_storage=mongo_storage,\n",
    "    postgres_storage=postgres_storage,\n",
    "    wiki_articles_count=1,\n",
    "    habr_posts_count=-1,\n",
    "    habs_list=['Машинное обучение']    \n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ml_habs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning:  bert\n",
      "bert это модель побившая несколько рекордов по успешности решения ряда nlpзадач\n",
      "bert одна из них это смеси распределений что может говорить о том чтобы я прочитал все то что математическая логика в состоянии описать может быть формализовано и выполнено машиной\n",
      "bert это языковая модель отgoogle показавшая stateoftheart результаты сбольшим отрывом нацелом ряде задач\n",
      "bert нет\n",
      "bert предобучается на двух задачах с неразмеченными текстами\n",
      "bert показал выдающиеся результаты по сравнению с предыдущим годом\n",
      "bert для текста cnn для картинки получаем контекстные представления элементов на странице для которых требуются разные метки обычно разделены хотя бы одним отсутствующим параметром\n",
      "bert нет\n",
      "bert\n",
      "bert не рассматривает слова как токены\n",
      "bert же напротив использует блоки энкодера\n",
      "bert от google ai который признан лучшим докладом года по мнению североамериканского отделения ассоциации компьютерной лингвистики\n",
      "bert получал во многих тестах оценки близкие к тому что начальные шаги действительно ведут нас по направлению к обрыву\n",
      "bert показал выдающиеся результаты по сравнению с asic\n",
      "bert достиг показателя что как сказали авторы было неожиданно\n",
      "bert получал во многих тестах оценки близкие к тому что в случае градиентного бустинга над решающими деревьями\n",
      "bert от google это образы debian которые прямо из коробки хоть и медленнее чем ожидалось\n",
      "bert выдат n эмбеддингый эмбеддинг содержит контекст всего предложенияподход ребят заключается в том что у белка очень высокая вариативность\n",
      "bert для извлечения признаков из изображения\n",
      "bert это модель побившая несколько рекордов по успешности решения ряда nlpзадач\n",
      "\n",
      "Finally:\n",
      " получал во многих тестах оценки близкие к тому что начальные шаги действительно ведут нас по направлению к обрыву\n",
      "показал выдающиеся результаты по сравнению с предыдущим годом\n",
      "это языковая модель отgoogle показавшая stateoftheart результаты сбольшим отрывом нацелом ряде задач\n",
      "не рассматривает слова как токены\n",
      "для извлечения признаков из изображения\n",
      "от google ai который признан лучшим докладом года по мнению североамериканского отделения ассоциации компьютерной лингвистики\n",
      "достиг показателя что как сказали авторы было неожиданно\n",
      "одна из них это смеси распределений что может говорить о том чтобы я прочитал все то что математическая логика в состоянии описать может быть формализовано и выполнено машиной\n",
      "же напротив использует блоки энкодера\n",
      "от google это образы debian которые прямо из коробки хоть и медленнее чем ожидалось\n",
      "получал во многих тестах оценки близкие к тому что в случае градиентного бустинга над решающими деревьями\n",
      "выдат n эмбеддингый эмбеддинг содержит контекст всего предложенияподход ребят заключается в том что у белка очень высокая вариативность\n",
      "это модель побившая несколько рекордов по успешности решения ряда nlpзадач\n",
      "предобучается на двух задачах с неразмеченными текстами\n",
      "показал выдающиеся результаты по сравнению с asic\n",
      "для текста cnn для картинки получаем контекстные представления элементов на странице для которых требуются разные метки обычно разделены хотя бы одним отсутствующим параметром\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['получал во многих тестах оценки близкие к тому что начальные шаги действительно ведут нас по направлению к обрыву',\n",
       " 'показал выдающиеся результаты по сравнению с предыдущим годом',\n",
       " 'это языковая модель отgoogle показавшая stateoftheart результаты сбольшим отрывом нацелом ряде задач',\n",
       " 'не рассматривает слова как токены',\n",
       " 'для извлечения признаков из изображения',\n",
       " 'от google ai который признан лучшим докладом года по мнению североамериканского отделения ассоциации компьютерной лингвистики',\n",
       " 'достиг показателя что как сказали авторы было неожиданно',\n",
       " 'одна из них это смеси распределений что может говорить о том чтобы я прочитал все то что математическая логика в состоянии описать может быть формализовано и выполнено машиной',\n",
       " 'же напротив использует блоки энкодера',\n",
       " 'от google это образы debian которые прямо из коробки хоть и медленнее чем ожидалось',\n",
       " 'получал во многих тестах оценки близкие к тому что в случае градиентного бустинга над решающими деревьями',\n",
       " 'выдат n эмбеддингый эмбеддинг содержит контекст всего предложенияподход ребят заключается в том что у белка очень высокая вариативность',\n",
       " 'это модель побившая несколько рекордов по успешности решения ряда nlpзадач',\n",
       " 'предобучается на двух задачах с неразмеченными текстами',\n",
       " 'показал выдающиеся результаты по сравнению с asic',\n",
       " 'для текста cnn для картинки получаем контекстные представления элементов на странице для которых требуются разные метки обычно разделены хотя бы одним отсутствующим параметром']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.make_sentences_for_t9('bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_model = MarkovModel.load('math_habs.json')\n",
    "ml_model = MarkovModel.load('ml_habs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.markov.combine import combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not implemented for compiled EncodedChain",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e196e25736bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmath_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/articles-gen/models/markov/combine.py\u001b[0m in \u001b[0;36mcombine\u001b[0;34m(models, weights)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`models` and `weights` lengths must be equal.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     state_sizes = [ len(list(md.keys())[0])\n\u001b[1;32m     31\u001b[0m         for md in model_dicts ]\n",
      "\u001b[0;32m~/PycharmProjects/articles-gen/models/markov/combine.py\u001b[0m in \u001b[0;36mget_model_dict\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncodedText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not implemented for compiled EncodedChain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mthing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not implemented for compiled EncodedChain"
     ]
    }
   ],
   "source": [
    "combined_model = combine([math_model.model, ml_model.model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
